{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            # [3, 32, 32]\n",
    "            nn.Conv2d(3, 64, 3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2),\n",
    "            # [64, 16, 16]\n",
    "            nn.Conv2d(64, 128, 3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2),\n",
    "            # [128, 8, 8]\n",
    "            nn.Conv2d(128, 256, 3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2)\n",
    "            # [256, 4, 4] -> latent shape: 4096\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 5, stride=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 9, stride=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 3, 17, stride=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.encoder(x)\n",
    "        x = self.decoder(x1)\n",
    "        return x1, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "def preprocess(image_list):\n",
    "    '''\n",
    "    Normalize Image and Permute (N,H,W,C) to (N,C,W,H)\n",
    "    :param image_list: list of images (9000, 32, 32, 3)\n",
    "    :return: image_list: list of images (9000, 3, 32, 32)\n",
    "    '''\n",
    "    image_list = np.array(image_list)\n",
    "    image_list = np.transpose(image_list, (0, 3, 1, 2))\n",
    "    image_list = (image_list / 255.0) * 2 - 1\n",
    "    image_list = image_list.astype(np.float32)\n",
    "    return image_list\n",
    "\n",
    "\n",
    "class ImgDataSet(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.data[item]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def save_model(model, dir, args):\n",
    "    if args['n_gpu'] > 1:\n",
    "        torch.save(model.state_dict(), dir+'.pth')\n",
    "    model = model.to(torch.device('cpu'))\n",
    "    torch.save(model, dir+'-cpu.pth')\n",
    "    print('-' * 20)\n",
    "    print('Save Success!')\n",
    "\n",
    "\n",
    "def count_parameters(model, only_trainable=False):\n",
    "    '''\n",
    "    count the number of parameters need to train\n",
    "    :param model:\n",
    "    :param only_trainable:\n",
    "    :return:\n",
    "    '''\n",
    "    if only_trainable:\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    else:\n",
    "        return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "\n",
    "def same_seeds(seed):\n",
    "    '''\n",
    "    set the same seed to reproduce the result\n",
    "    :param seed:\n",
    "    :return:\n",
    "    '''\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    np.random.seed(seed)  # Numpy module.\n",
    "    random.seed(seed)  # Python random module.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def cal_acc(gt, pred):\n",
    "    '''\n",
    "    compute categorization accuracy of our task\n",
    "    :param gt:  ground truth labels (9000, )\n",
    "    :param pred: predicted labels (9000, )\n",
    "    :return:\n",
    "    '''\n",
    "    correct = np.sum(gt == pred)\n",
    "    acc = correct / gt.shape[0]\n",
    "    return max(acc, 1-acc)\n",
    "\n",
    "\n",
    "def plot_scatter(feat, label, savefig=None):\n",
    "    '''\n",
    "    plot scatter image\n",
    "    :param feat: the (x, y) coordinate of clustering result, shape (9000, 2)\n",
    "    :param label: ground truth label of image (0/1), shape (9000, 2)\n",
    "    :param savefig:\n",
    "    :return:\n",
    "    '''\n",
    "    X = feat[:, 0]\n",
    "    Y = feat[:, 1]\n",
    "    plt.scatter(X, Y, c=label)\n",
    "    plt.legend(loc='best')\n",
    "    if savefig is not None:\n",
    "        plt.savefig(savefig)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def train_loop(autoencoder, dataloader, args: dict):\n",
    "    device = args['device']\n",
    "    n_gpu = args['n_gpu']\n",
    "    epochs = args['epochs']\n",
    "    criterion = nn.MSELoss()\n",
    "    learning_rate = 1e-5\n",
    "    decay = 1e-5\n",
    "    opt = torch.optim.Adam(autoencoder.parameters(),\n",
    "                           lr=learning_rate,\n",
    "                           weight_decay=decay)\n",
    "\n",
    "    autoencoder.train()\n",
    "    mse_loss = 0\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        for batch in dataloader:\n",
    "            batch = batch.to(device)\n",
    "            hidden, out = autoencoder(batch)\n",
    "            loss = criterion(out, batch)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            if n_gpu > 1:\n",
    "                loss = loss.mean()\n",
    "            mse_loss += loss.item()\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            losses.append(mse_loss)\n",
    "            mse_loss = 0\n",
    "        print(\"epoch %d, mse loss: %.2f\" % (epoch, mse_loss))\n",
    "\n",
    "    return losses\n",
    "\n",
    "\n",
    "def eval(autoencoder, device, samples, dataset):\n",
    "    autoencoder = autoencoder.to(device)\n",
    "    autoencoder.eval()\n",
    "    dataloader = DataLoader(dataset,\n",
    "                            batch_size=1,\n",
    "                            shuffle=True)\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    with torch.no_grad():\n",
    "        for sample in range(samples):\n",
    "            input = next(iter(dataloader))\n",
    "            input = input.to(device)\n",
    "            hidden, output = autoencoder(input)\n",
    "            input = input[0]\n",
    "            input = np.transpose(input, (1, 2, 0))\n",
    "            inputs.append(input)\n",
    "            output = output[0]\n",
    "            output = np.transpose(output, (1, 2, 0))\n",
    "            outputs.append(output)\n",
    "\n",
    "        return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loading model...\n",
      "Setting cuda&cpu...\n",
      "device:  cpu\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m_/hzclb1xj54n3980rst8vsjhh0000gn/T/ipykernel_1759/1673003151.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'device'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n_gpu'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mn_gpu\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'losses.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/m_/hzclb1xj54n3980rst8vsjhh0000gn/T/ipykernel_1759/1860158174.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(autoencoder, dataloader, args)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/dl/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/dl/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print('Loading data...')\n",
    "train_data = np.load('./train.npy')\n",
    "test_data = np.load('./test.npy')\n",
    "train_data, test_data = preprocess(train_data), preprocess(test_data)\n",
    "dataset = ImgDataSet(train_data)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "print('Loading model...')\n",
    "model = AE()\n",
    "print('Setting cuda&cpu...')\n",
    "device = torch.device('cpu')\n",
    "n_gpu = 0\n",
    "if torch.cuda.is_available():\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    gpu_ids = list(range(0, n_gpu))\n",
    "    if n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(\n",
    "            model, device_ids=gpu_ids, output_device=gpu_ids[-1]\n",
    "        )\n",
    "        print('-> GPU training available! Training will use GPU(s) {}\\n'.format(gpu_ids))\n",
    "    device = torch.device('cuda')\n",
    "print('device: ', device)\n",
    "\n",
    "model = model.to(device)\n",
    "args = {'epochs': 10, 'device': device, 'n_gpu': n_gpu}\n",
    "save_model(model, 'AE', args)\n",
    "losses = train_loop(model, dataloader, args)\n",
    "\n",
    "np.save(losses, 'losses.npy')\n",
    "save_model(model, 'AE', args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b804d48c42c2a77efa362e13d57eab5908521665c300c35f3f0dfefc3c51474f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('dl': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
